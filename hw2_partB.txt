Running my implementation across all possible permutations, I yielded the results shown in output.tsv

From these results, the first thing I immediately differentiated by was term weighting. No matter what
other model parameters were used, boolean weighting performed worse than tf weighting which performed  
drastically worse than tf-idf. Take the following results for example:

boolean False   False   cosine  1,1,1,4 0.0023  0.0031  0.0039  0.0044  0.0031  0.0032  0.2786  0.0677
tf      False   False   cosine  1,1,1,4 0.0460  0.0217  0.0143  0.0061  0.0273  0.0289  0.5164  0.1595
tfidf   False   False   cosine  1,1,1,4 0.3227  0.2102  0.1233  0.0880  0.2187  0.2091  0.5146  0.1586

For p_0.25, for example, tf was just 0.0186 better than boolean, whereas tfidf was 0.2997 better than boolean. 
This is a factor of over 16 times greater. Since all other parameters were held constant, this gives 
definitive evidence that tfidf is, without contest, the superior term weighting approach. From there on out,
I tested permutations, keeping tfidf as a constant (term weighting) parameter.

I think that the reason boolean weighting performed the worst is because the simple fact of wheter or not 
a word occurs in a document does not reveal a lot of specific information about the document. For example, a 
document discussing school curricula could mention "comptuer science" once and it would be weighted the
same as a paper discussing pedagogy of computer science that mentions "computer science" 10s of times. 
Clearly, if someone queried to learn about "computer science," then the latter document would be much more
relevant, giving the far greater instances of the term. As such, term frequency performed better than boolean:
the actual number of instances is far more revealing and specifying than wheter or not there was at least one 
instance. 

